{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4037d004",
   "metadata": {},
   "source": [
    "# Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8275f",
   "metadata": {},
   "source": [
    "#### Github Link: https://github.com/hennypurwadi/SentimentAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d26f112",
   "metadata": {},
   "source": [
    "#### Dataset link:https://www.kaggle.com/datasets/d4rklucif3r/restaurant-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5354472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: schedule in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install nltk\n",
    "#!pip install streamlit\n",
    "!pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4fbf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import csv\n",
    "#nltk.download()\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import trigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV,KFold\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,confusion_matrix,recall_score,precision_score,classification_report,roc_curve, auc\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "import schedule\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251cbcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Liked\n",
       "0                           Wow... Loved this place.     1\n",
       "1                                 Crust is not good.     0\n",
       "2          Not tasty and the texture was just nasty.     0\n",
       "3  Stopped by during the late May bank holiday of...     1\n",
       "4  The selection on the menu was great and so wer...     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Restaurant_Reviews.csv', encoding='utf-8')\n",
    "#Change type from into str\n",
    "df = df.applymap(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd60daf",
   "metadata": {},
   "source": [
    "### The Label's column \"Liked\" only divided into 2 sentiment categories: 1 is positive, 0 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8e09168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Liked\n",
       "0                           Wow... Loved this place.  positive\n",
       "1                                 Crust is not good.  negative\n",
       "2          Not tasty and the texture was just nasty.  negative\n",
       "3  Stopped by during the late May bank holiday of...  positive\n",
       "4  The selection on the menu was great and so wer...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Liked'].dtype\n",
    "df1= df.replace({'Liked': {'1': 'positive','0': 'negative'}})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b3e73e",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9b26c",
   "metadata": {},
   "source": [
    "## Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136fc343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Liked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1.isnull().sum()\n",
    "df1 = df1.dropna()\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812d146",
   "metadata": {},
   "source": [
    "### Cleaning with Regex\n",
    "Preprocessing, Cleaning with regex\n",
    "Make the text lowercase, remove line breaks, punctuation, usernames, url, extra spaces, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c2220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow loved this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "      <td>crust is not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>positive</td>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>positive</td>\n",
       "      <td>the selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>negative</td>\n",
       "      <td>now am getting angry and want my damn pho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>negative</td>\n",
       "      <td>honeslty it didn taste that fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>negative</td>\n",
       "      <td>the potatoes were like rubber and you could te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>positive</td>\n",
       "      <td>the fries were great too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>positive</td>\n",
       "      <td>great touch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Liked  \\\n",
       "0                           Wow... Loved this place.  positive   \n",
       "1                                 Crust is not good.  negative   \n",
       "2          Not tasty and the texture was just nasty.  negative   \n",
       "3  Stopped by during the late May bank holiday of...  positive   \n",
       "4  The selection on the menu was great and so wer...  positive   \n",
       "5     Now I am getting angry and I want my damn pho.  negative   \n",
       "6              Honeslty it didn't taste THAT fresh.)  negative   \n",
       "7  The potatoes were like rubber and you could te...  negative   \n",
       "8                          The fries were great too.  positive   \n",
       "9                                     A great touch.  positive   \n",
       "\n",
       "                                       Clean_Reviews  \n",
       "0                               wow loved this place  \n",
       "1                                  crust is not good  \n",
       "2           not tasty and the texture was just nasty  \n",
       "3  stopped by during the late may bank holiday of...  \n",
       "4  the selection on the menu was great and so wer...  \n",
       "5          now am getting angry and want my damn pho  \n",
       "6                  honeslty it didn taste that fresh  \n",
       "7  the potatoes were like rubber and you could te...  \n",
       "8                           the fries were great too  \n",
       "9                                        great touch  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning(Review_data):   \n",
    "    Review_data = str(Review_data).lower()\n",
    "    Review_data = re.sub(r'#[A-Za-z0–9]+', '', Review_data) #remove hashtags\n",
    "    Review_data=re.sub(r'@[A-Za-z0–9]+', '',Review_data) #remove usernames    \n",
    "    Review_data=re.sub(r'@\\w+', ' ', Review_data) #remove usernames\n",
    "    Review_data= re.sub(r'\\b\\w{1}\\b', '', Review_data) #remove stopwords   \n",
    "    Review_data = re.sub(r'&(?![A-Za-z]+[0-9]*;|#[0-9]+;|#x[0-9a-fA-F]+;)', '', Review_data)\n",
    "    Review_data = re.sub(r'&amp', '', Review_data) \n",
    "    Review_data = re.sub('\\n', '', Review_data) #Remove line breaks.\n",
    "    Review_data = re.sub('[%s]' % re.escape(string.punctuation), '', Review_data) #remove punctuation\n",
    "    Review_data = re.sub('\\[.*?\\]', '', Review_data)\n",
    "    Review_data=re.sub(r'http\\S+', ' ', Review_data) #remove all Url\n",
    "    Review_data = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', Review_data) #remove website\n",
    "    Review_data = re.sub('https?://\\S+|www\\.\\S+', '', Review_data)  #remove all websites \n",
    "    Review_data = re.sub(r' +', ' ', Review_data) #remove extra space\n",
    "    Review_data = re.sub('<.*?>+', '', Review_data)    \n",
    "    Review_data = re.sub('\\w*\\d\\w*', '', Review_data)\n",
    "    Review_data = re.sub(r'^RT[\\s]+', '', Review_data)    \n",
    "    Review_data = re.sub(r'[^a-z A-Z]', ' ',Review_data) #Remove all not characters\n",
    "    return Review_data\n",
    "\n",
    "df1['Clean_Reviews'] = df1['Review'].apply(cleaning)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7edddf",
   "metadata": {},
   "source": [
    "### Lemitization with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ae53102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow loved this place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "      <td>crust is not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "      <td>not tasty and the texture wa just nasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>positive</td>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>positive</td>\n",
       "      <td>the selection on the menu wa great and so were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>negative</td>\n",
       "      <td>now am getting angry and want my damn pho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>negative</td>\n",
       "      <td>honeslty it didn taste that fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>negative</td>\n",
       "      <td>the potato were like rubber and you could tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>positive</td>\n",
       "      <td>the fry were great too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>positive</td>\n",
       "      <td>great touch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Liked  \\\n",
       "0                           Wow... Loved this place.  positive   \n",
       "1                                 Crust is not good.  negative   \n",
       "2          Not tasty and the texture was just nasty.  negative   \n",
       "3  Stopped by during the late May bank holiday of...  positive   \n",
       "4  The selection on the menu was great and so wer...  positive   \n",
       "5     Now I am getting angry and I want my damn pho.  negative   \n",
       "6              Honeslty it didn't taste THAT fresh.)  negative   \n",
       "7  The potatoes were like rubber and you could te...  negative   \n",
       "8                          The fries were great too.  positive   \n",
       "9                                     A great touch.  positive   \n",
       "\n",
       "                                       Clean_Reviews  \n",
       "0                               wow loved this place  \n",
       "1                                  crust is not good  \n",
       "2            not tasty and the texture wa just nasty  \n",
       "3  stopped by during the late may bank holiday of...  \n",
       "4  the selection on the menu wa great and so were...  \n",
       "5          now am getting angry and want my damn pho  \n",
       "6                  honeslty it didn taste that fresh  \n",
       "7  the potato were like rubber and you could tell...  \n",
       "8                             the fry were great too  \n",
       "9                                        great touch  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##lemmatization to bring the words in their root form  \n",
    "lem = WordNetLemmatizer()\n",
    "df1['Clean_Reviews'] = df1['Clean_Reviews'].apply(\n",
    "    lambda x: \" \".join([lem.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572f9e1",
   "metadata": {},
   "source": [
    "### Stemming with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4fa991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow love thi place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "      <td>crust is not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "      <td>not tasti and the textur wa just nasti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>positive</td>\n",
       "      <td>stop by dure the late may bank holiday off ric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>positive</td>\n",
       "      <td>the select on the menu wa great and so were th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>negative</td>\n",
       "      <td>now am get angri and want my damn pho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>negative</td>\n",
       "      <td>honeslti it didn tast that fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>negative</td>\n",
       "      <td>the potato were like rubber and you could tell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>positive</td>\n",
       "      <td>the fri were great too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>positive</td>\n",
       "      <td>great touch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Liked  \\\n",
       "0                           Wow... Loved this place.  positive   \n",
       "1                                 Crust is not good.  negative   \n",
       "2          Not tasty and the texture was just nasty.  negative   \n",
       "3  Stopped by during the late May bank holiday of...  positive   \n",
       "4  The selection on the menu was great and so wer...  positive   \n",
       "5     Now I am getting angry and I want my damn pho.  negative   \n",
       "6              Honeslty it didn't taste THAT fresh.)  negative   \n",
       "7  The potatoes were like rubber and you could te...  negative   \n",
       "8                          The fries were great too.  positive   \n",
       "9                                     A great touch.  positive   \n",
       "\n",
       "                                       Clean_Reviews  \n",
       "0                                 wow love thi place  \n",
       "1                                  crust is not good  \n",
       "2             not tasti and the textur wa just nasti  \n",
       "3  stop by dure the late may bank holiday off ric...  \n",
       "4  the select on the menu wa great and so were th...  \n",
       "5              now am get angri and want my damn pho  \n",
       "6                   honeslti it didn tast that fresh  \n",
       "7  the potato were like rubber and you could tell...  \n",
       "8                             the fri were great too  \n",
       "9                                        great touch  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm = PorterStemmer()\n",
    "df1['Clean_Reviews'] = df1['Clean_Reviews'].apply(\n",
    "    lambda x: \" \".join([stm.stem(word) for word in x.split()]))\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88b537",
   "metadata": {},
   "source": [
    "### Remove stopwords with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f3909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "      <th>Cleaned_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>wow love thi place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "      <td>crust is not good</td>\n",
       "      <td>crust good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "      <td>not tasti and the textur wa just nasti</td>\n",
       "      <td>tasti textur wa nasti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>positive</td>\n",
       "      <td>stop by dure the late may bank holiday off ric...</td>\n",
       "      <td>stop dure late may bank holiday rick steve rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>positive</td>\n",
       "      <td>the select on the menu wa great and so were th...</td>\n",
       "      <td>select menu wa great price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Liked  \\\n",
       "0                           Wow... Loved this place.  positive   \n",
       "1                                 Crust is not good.  negative   \n",
       "2          Not tasty and the texture was just nasty.  negative   \n",
       "3  Stopped by during the late May bank holiday of...  positive   \n",
       "4  The selection on the menu was great and so wer...  positive   \n",
       "\n",
       "                                       Clean_Reviews  \\\n",
       "0                                 wow love thi place   \n",
       "1                                  crust is not good   \n",
       "2             not tasti and the textur wa just nasti   \n",
       "3  stop by dure the late may bank holiday off ric...   \n",
       "4  the select on the menu wa great and so were th...   \n",
       "\n",
       "                                     Cleaned_Reviews  \n",
       "0                                 wow love thi place  \n",
       "1                                         crust good  \n",
       "2                              tasti textur wa nasti  \n",
       "3  stop dure late may bank holiday rick steve rec...  \n",
       "4                         select menu wa great price  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english') \n",
    "df1['Cleaned_Reviews'] = df1['Clean_Reviews'].apply(\n",
    "    lambda x: \" \".join(x for x in x.split() if x not in stopwords))\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe0abc",
   "metadata": {},
   "source": [
    "### Add \"neutral\" sentiment into dataset which only have \"positive\" and \"negative\" sentiment\n",
    "### using pre-trained Vader, nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d5852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0fc55b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound': 0.8402}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(df1.loc[0]['Cleaned_Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925dc151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "      <th>Score</th>\n",
       "      <th>compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound...</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "      <td>crust is not good</td>\n",
       "      <td>{'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "      <td>not tasti and the textur wa just nasti</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>positive</td>\n",
       "      <td>stop by dure the late may bank holiday off ric...</td>\n",
       "      <td>{'neg': 0.097, 'neu': 0.487, 'pos': 0.416, 'co...</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>positive</td>\n",
       "      <td>the select on the menu wa great and so were th...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.728, 'pos': 0.272, 'comp...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Liked  \\\n",
       "0                           Wow... Loved this place.  positive   \n",
       "1                                 Crust is not good.  negative   \n",
       "2          Not tasty and the texture was just nasty.  negative   \n",
       "3  Stopped by during the late May bank holiday of...  positive   \n",
       "4  The selection on the menu was great and so wer...  positive   \n",
       "\n",
       "                                       Clean_Reviews  \\\n",
       "0                                 wow love thi place   \n",
       "1                                  crust is not good   \n",
       "2             not tasti and the textur wa just nasti   \n",
       "3  stop by dure the late may bank holiday off ric...   \n",
       "4  the select on the menu wa great and so were th...   \n",
       "\n",
       "                                               Score  compound Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound...    0.8402  positive  \n",
       "1  {'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'comp...   -0.3412  negative  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  negative  \n",
       "3  {'neg': 0.097, 'neu': 0.487, 'pos': 0.416, 'co...    0.8020  positive  \n",
       "4  {'neg': 0.0, 'neu': 0.728, 'pos': 0.272, 'comp...    0.6249  positive  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Score'] = df1['Clean_Reviews'].apply(lambda Cleaned_Reviews: sid.polarity_scores(Cleaned_Reviews))\n",
    "df1['compound']  = df1['Score'].apply(lambda score_dict: score_dict['compound'])\n",
    "df1['Sentiment'] = df1['compound'].apply(lambda c: 'positive' if c > 0 else ('negative' if c < 0 else 'negative'))\n",
    "df1[['Review','Liked','Clean_Reviews','Score','compound','Sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6aecb",
   "metadata": {},
   "source": [
    "### Divide into 2 sentiment categories: positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2fbc6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Review'][3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e4bfb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The selection on the menu was great and so were the prices.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Review'][4] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1ee390",
   "metadata": {},
   "source": [
    "### Count Accuracy\n",
    "### Comparing label \"Liked\" column vs \"sentiment\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc47ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d199056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.76      0.72       500\n",
      "    positive       0.73      0.65      0.69       500\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.71      0.70      0.70      1000\n",
      "weighted avg       0.71      0.70      0.70      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df1['Liked'],df1['Sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46cdd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[380 120]\n",
      " [177 323]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df1['Liked'],df1['Sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48080ea",
   "metadata": {},
   "source": [
    "### Accuracy is quite good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b872d50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df1['Liked'],df1['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d81f42",
   "metadata": {},
   "source": [
    "## Divide into 3 categories: Positive, Negative, Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5e793e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "      <th>Score</th>\n",
       "      <th>compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound...</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "      <td>crust is not good</td>\n",
       "      <td>{'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "      <td>not tasti and the textur wa just nasti</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>positive</td>\n",
       "      <td>stop by dure the late may bank holiday off ric...</td>\n",
       "      <td>{'neg': 0.097, 'neu': 0.487, 'pos': 0.416, 'co...</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>positive</td>\n",
       "      <td>the select on the menu wa great and so were th...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.728, 'pos': 0.272, 'comp...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Liked  \\\n",
       "0                           Wow... Loved this place.  positive   \n",
       "1                                 Crust is not good.  negative   \n",
       "2          Not tasty and the texture was just nasty.  negative   \n",
       "3  Stopped by during the late May bank holiday of...  positive   \n",
       "4  The selection on the menu was great and so wer...  positive   \n",
       "\n",
       "                                       Clean_Reviews  \\\n",
       "0                                 wow love thi place   \n",
       "1                                  crust is not good   \n",
       "2             not tasti and the textur wa just nasti   \n",
       "3  stop by dure the late may bank holiday off ric...   \n",
       "4  the select on the menu wa great and so were th...   \n",
       "\n",
       "                                               Score  compound Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound...    0.8402  positive  \n",
       "1  {'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'comp...   -0.3412  negative  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   neutral  \n",
       "3  {'neg': 0.097, 'neu': 0.487, 'pos': 0.416, 'co...    0.8020  positive  \n",
       "4  {'neg': 0.0, 'neu': 0.728, 'pos': 0.272, 'comp...    0.6249  positive  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Sentiment'] = df1['compound'].apply(lambda c: 'positive' if c > 0 else ('negative' if c < 0 else 'neutral'))\n",
    "df1[['Review','Liked','Clean_Reviews','Score','compound','Sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95e5b6",
   "metadata": {},
   "source": [
    "## Count each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cb2b054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    443\n",
       "neutral     352\n",
       "negative    205\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_count = df1['Sentiment'].value_counts()\n",
    "sentiment_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8880fa92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_users=sentiment_count.plot.pie(autopct='%1.1f%%', figsize=(5, 5))\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "plt.savefig(\"sentiment_count_chart.jpeg\",transparent=False, bbox_inches='tight',pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd24b557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review     Liked\n",
       "0                           Wow... Loved this place.  positive\n",
       "1                                 Crust is not good.  negative\n",
       "2          Not tasty and the texture was just nasty.  negative\n",
       "3  Stopped by during the late May bank holiday of...  positive\n",
       "4  The selection on the menu was great and so wer...  positive"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[:, 0:2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da8968ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "      <th>Cleaned_Reviews</th>\n",
       "      <th>Score</th>\n",
       "      <th>compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound...</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "      <td>crust is not good</td>\n",
       "      <td>crust good</td>\n",
       "      <td>{'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>negative</td>\n",
       "      <td>not tasti and the textur wa just nasti</td>\n",
       "      <td>tasti textur wa nasti</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Review     Liked  \\\n",
       "0                   Wow... Loved this place.  positive   \n",
       "1                         Crust is not good.  negative   \n",
       "2  Not tasty and the texture was just nasty.  negative   \n",
       "\n",
       "                            Clean_Reviews        Cleaned_Reviews  \\\n",
       "0                      wow love thi place     wow love thi place   \n",
       "1                       crust is not good             crust good   \n",
       "2  not tasti and the textur wa just nasti  tasti textur wa nasti   \n",
       "\n",
       "                                               Score  compound Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound...    0.8402  positive  \n",
       "1  {'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'comp...   -0.3412  negative  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   neutral  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c435f1",
   "metadata": {},
   "source": [
    "## Replace value become \"neutral\"  in \"Liked\" column, if compound == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e1060d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Liked'].mask(df1['compound'] ==0 ,'neutral', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11bb5b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "      <th>Cleaned_Reviews</th>\n",
       "      <th>Score</th>\n",
       "      <th>compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound...</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>negative</td>\n",
       "      <td>crust is not good</td>\n",
       "      <td>crust good</td>\n",
       "      <td>{'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>not tasti and the textur wa just nasti</td>\n",
       "      <td>tasti textur wa nasti</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Review     Liked  \\\n",
       "0                   Wow... Loved this place.  positive   \n",
       "1                         Crust is not good.  negative   \n",
       "2  Not tasty and the texture was just nasty.   neutral   \n",
       "\n",
       "                            Clean_Reviews        Cleaned_Reviews  \\\n",
       "0                      wow love thi place     wow love thi place   \n",
       "1                       crust is not good             crust good   \n",
       "2  not tasti and the textur wa just nasti  tasti textur wa nasti   \n",
       "\n",
       "                                               Score  compound Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.2, 'pos': 0.8, 'compound...    0.8402  positive  \n",
       "1  {'neg': 0.445, 'neu': 0.555, 'pos': 0.0, 'comp...   -0.3412  negative  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000   neutral  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77359b4c",
   "metadata": {},
   "source": [
    "## Write into new .csv dataset which have 3 sentiments\n",
    "### 1 == positive, 0 == neutral, -1 == negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d77a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done saving\n"
     ]
    }
   ],
   "source": [
    "#df1[['Review','Sentiment']].to_csv('Restaurant_Reviews_pos_neu_neg.csv', encoding='utf-8')\n",
    "df2 = df1.drop(columns=['Clean_Reviews','Cleaned_Reviews','Score','compound','Sentiment']).replace(\n",
    "    {'Liked': {'positive':'1','neutral': '0','negative': '-1'}}).to_csv(\n",
    "    'Restaurant_Reviews_pos_neu_neg.csv', encoding='utf-8',  index=False)\n",
    "print(\"done saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6608f3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wow... Loved this place.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crust is not good.</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not tasty and the texture was just nasty.</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The selection on the menu was great and so were the prices.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Liked\n",
       "Review                                                  \n",
       "Wow... Loved this place.                               1\n",
       "Crust is not good.                                    -1\n",
       "Not tasty and the texture was just nasty.              0\n",
       "Stopped by during the late May bank holiday off...     1\n",
       "The selection on the menu was great and so were...     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv('Restaurant_Reviews_pos_neu_neg.csv', encoding='utf-8',index_col=0)\n",
    "#Change type from into strindex_col=0\n",
    "df2 = df2.applymap(str)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ba04fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wow... Loved this place.</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crust is not good.</th>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not tasty and the texture was just nasty.</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The selection on the menu was great and so were the prices.</th>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Liked\n",
       "Review                                                      \n",
       "Wow... Loved this place.                            positive\n",
       "Crust is not good.                                  negative\n",
       "Not tasty and the texture was just nasty.            neutral\n",
       "Stopped by during the late May bank holiday off...  positive\n",
       "The selection on the menu was great and so were...  positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= df2.replace({'Liked': {'1': 'positive','0': 'neutral','-1': 'negative'}})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9fd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a26c5663",
   "metadata": {},
   "source": [
    "# Vectorize cleaned texts with Tf-IDF with ngram_range\n",
    "ngram_range of (1, 1) means only unigrams. (1, 2) means unigrams and bigrams. (1, 3) means unigrams, bigrams, and trigrams. (2, 2) means only bigrams.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1be843b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x9063 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13710 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=1 ,max_df=0.95, ngram_range=(1,3),stop_words='english', lowercase=True, smooth_idf=True)\n",
    "tfidf_text = tfidf.fit_transform(df1['Clean_Reviews'])\n",
    "tfidf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a19e31",
   "metadata": {},
   "source": [
    "# Train, Test model with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd14541",
   "metadata": {},
   "source": [
    "## Preprocessing and Cleaning with function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43144260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(preprocessedtext):   \n",
    "    \n",
    "    processedText = []\n",
    "    for Review_data in preprocessedtext:\n",
    "        Review_data = str(Review_data).lower()\n",
    "        Review_data = re.sub(r'#[A-Za-z0–9]+', '', Review_data) #remove hashtags\n",
    "        Review_data=re.sub(r'@[A-Za-z0–9]+', '',Review_data) #remove usernames    \n",
    "        Review_data=re.sub(r'@\\w+', ' ', Review_data) #remove usernames\n",
    "        Review_data= re.sub(r'\\b\\w{1}\\b', '', Review_data) #remove stopwords   \n",
    "        Review_data = re.sub(r'&(?![A-Za-z]+[0-9]*;|#[0-9]+;|#x[0-9a-fA-F]+;)', '', Review_data)\n",
    "        Review_data = re.sub(r'&amp', '', Review_data) \n",
    "        Review_data = re.sub('\\n', '', Review_data) #Remove line breaks.\n",
    "        Review_data = re.sub('[%s]' % re.escape(string.punctuation), '', Review_data) #remove punctuation\n",
    "        Review_data = re.sub('\\[.*?\\]', '', Review_data)\n",
    "        Review_data=re.sub(r'http\\S+', ' ', Review_data) #remove all Url\n",
    "        Review_data = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', Review_data) #remove website\n",
    "        Review_data = re.sub('https?://\\S+|www\\.\\S+', '', Review_data)  #remove all websites \n",
    "        Review_data = re.sub(r' +', ' ', Review_data) #remove extra space\n",
    "        Review_data = re.sub('<.*?>+', '', Review_data)    \n",
    "        Review_data = re.sub('\\w*\\d\\w*', '', Review_data)\n",
    "        Review_data = re.sub(r'^RT[\\s]+', '', Review_data)    \n",
    "        Review_data = re.sub(r'[^a-z A-Z]', ' ',Review_data) #Remove all not characters\n",
    "        \n",
    "        processedText.append(Review_data)\n",
    "        \n",
    "    return processedText\n",
    "\n",
    "def get_jvnr(tag):\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    if tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    if tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def stemming_process(preprocessedtext):\n",
    "    # Create stemming\n",
    "    stm = PorterStemmer()\n",
    "   \n",
    "    finalprocessedtext = []\n",
    "    for word in preprocessedtext:\n",
    "        text_pos = pos_tag(word_tokenize(word))\n",
    "        words = [x[0] for x in text_pos]\n",
    "        pos = [x[1] for x in text_pos]\n",
    "        word_stm = \" \".join([stm.stem(a,get_jvnr(b)) for a,b in zip(words,pos)])\n",
    "        finalprocessedtext.append(word_stm)\n",
    "    return finalprocessedtext\n",
    "\n",
    "def lemmatize_process(preprocessedtext):\n",
    "    # Create lemmatizer\n",
    "    lemma = WordNetLemmatizer()\n",
    "   \n",
    "    finalprocessedtext = []\n",
    "    for word in preprocessedtext:\n",
    "        text_pos = pos_tag(word_tokenize(word))\n",
    "        words = [x[0] for x in text_pos]\n",
    "        pos = [x[1] for x in text_pos]\n",
    "        word_stm = \" \".join([lem.lemmatize(a,get_jvnr(b)) for a,b in zip(words,pos)])\n",
    "        finalprocessedtext.append(word_stm)\n",
    "    return finalprocessedtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d3e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae69152b",
   "metadata": {},
   "source": [
    "# Split the Data become train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76af2a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Data Split\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into train and test, test size of 3%\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1.Clean_Reviews, df1.Liked, test_size = 0.03, random_state = 0)\n",
    "print('Done Data Split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46d8687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Transformed.\n"
     ]
    }
   ],
   "source": [
    "X_train = tfidf.transform(X_train)\n",
    "X_test  = tfidf.transform(X_test)\n",
    "print(f'Data Transformed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22b62ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Clean_Reviews</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>wow love thi place</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>crust is not good</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>not tasti and the textur wa just nasti</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>stop by dure the late may bank holiday off ric...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>the select on the menu wa great and so were th...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>now am get angri and want my damn pho</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>honeslti it didn tast that fresh</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>the potato were like rubber and you could tell...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>the fri were great too</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>great touch</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0                           Wow... Loved this place.   \n",
       "1                                 Crust is not good.   \n",
       "2          Not tasty and the texture was just nasty.   \n",
       "3  Stopped by during the late May bank holiday of...   \n",
       "4  The selection on the menu was great and so wer...   \n",
       "5     Now I am getting angry and I want my damn pho.   \n",
       "6              Honeslty it didn't taste THAT fresh.)   \n",
       "7  The potatoes were like rubber and you could te...   \n",
       "8                          The fries were great too.   \n",
       "9                                     A great touch.   \n",
       "\n",
       "                                       Clean_Reviews     Liked  \n",
       "0                                 wow love thi place  positive  \n",
       "1                                  crust is not good  negative  \n",
       "2             not tasti and the textur wa just nasti   neutral  \n",
       "3  stop by dure the late may bank holiday off ric...  positive  \n",
       "4  the select on the menu wa great and so were th...  positive  \n",
       "5              now am get angri and want my damn pho  negative  \n",
       "6                   honeslti it didn tast that fresh  negative  \n",
       "7  the potato were like rubber and you could tell...  negative  \n",
       "8                             the fri were great too  positive  \n",
       "9                                        great touch  positive  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[['Review','Clean_Reviews','Liked']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d61e71",
   "metadata": {},
   "source": [
    "# Compare Model's accuracy : LinearSVC, Bernoulli NB, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaba1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Evaluate(model):\n",
    "    \n",
    "    # Predict values for Test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print the evaluation metrics for the dataset.\n",
    "    print(classification_report(y_test, y_pred))   \n",
    "    \n",
    "    #return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41397b12",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ea0ff5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        10\n",
      "     neutral       0.38      1.00      0.55         9\n",
      "    positive       1.00      0.55      0.71        11\n",
      "\n",
      "    accuracy                           0.50        30\n",
      "   macro avg       0.46      0.52      0.42        30\n",
      "weighted avg       0.48      0.50      0.42        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BNBmodel = BernoulliNB(alpha = 2)\n",
    "BNBmodel.fit(X_train, y_train)\n",
    "model_Evaluate(BNBmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f278219",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78d115e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.70      0.78        10\n",
      "     neutral       0.73      0.89      0.80         9\n",
      "    positive       0.82      0.82      0.82        11\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.81      0.80      0.80        30\n",
      "weighted avg       0.81      0.80      0.80        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVCmodel = LinearSVC()\n",
    "SVCmodel.fit(X_train, y_train)\n",
    "model_Evaluate(SVCmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede17409",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92b721cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.60      0.71        10\n",
      "     neutral       0.73      0.89      0.80         9\n",
      "    positive       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.81      0.80      0.79        30\n",
      "weighted avg       0.81      0.80      0.79        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRmodel = LogisticRegression(C = 1, max_iter = 1000, n_jobs=-1)\n",
    "LogReg = LRmodel.fit(X_train, y_train)\n",
    "y_test_pred = model_Evaluate(LRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ad46c",
   "metadata": {},
   "source": [
    "##### Logistic Regression accuracy is around 80% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0fc31",
   "metadata": {},
   "source": [
    "# Save the Logistic Regression Model\n",
    "#### Using PICKLE to save tfidf and Logistic Regression Model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6473940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models():\n",
    "    file = open('vectorizer.pickle','wb')\n",
    "    pickle.dump(tfidf, file)\n",
    "    file.close()\n",
    "\n",
    "    file = open('sentimentanalysis_LR.pickle','wb')\n",
    "    pickle.dump(LRmodel, file)\n",
    "    file.close()\n",
    "    \n",
    "    print(\"Models saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22c7ec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved\n"
     ]
    }
   ],
   "source": [
    "train_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80fc81",
   "metadata": {},
   "source": [
    "# Use the Logistic Regression Model and Vectorized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6b45d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():  \n",
    "       \n",
    "    # Load the vectorizer.\n",
    "    file = open('vectorizer.pickle', 'rb')\n",
    "    vectorizer = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    # Load the LR Model.\n",
    "    file = open('sentimentanalysis_LR.pickle', 'rb')\n",
    "    LRmodel = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return vectorizer, LRmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85198630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_a(vectorizer, model, text):\n",
    "    finaldata_a = []\n",
    "\n",
    "    textdata_a = vectorizer.transform((lemmatize_process(stemming_process(preprocess(text)))))\n",
    "    sentiment_a = model.predict(textdata_a)\n",
    "    sentimentp_a = model.predict_proba(textdata_a)\n",
    "    \n",
    "    for index,sentences in enumerate(text):\n",
    "        if sentiment_a[index] == 0:\n",
    "            sentimentp_aFinal = sentimentp_a[index][0]\n",
    "        else:  \n",
    "            sentimentp_aFinal = sentimentp_a[index][1]\n",
    "            \n",
    "        sentimentpFinal_a = \"{}%\".format(round(sentimentp_aFinal*100,2))\n",
    "        finaldata_a.append((sentences, sentiment_a[index], sentimentpFinal_a))\n",
    "           \n",
    "    return finaldata_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be4b3e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_a = [\"The purpose of life is to love\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0ce564b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The purpose of life is to love', 'positive', '15.27%')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer, LRmodel = load_models()\n",
    "text_a = predict_a(vectorizer, LRmodel, message_a)\n",
    "text_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056d0c5",
   "metadata": {},
   "source": [
    "# Create App with streamlit\n",
    "https://streamlit.io/\n",
    "https://docs.streamlit.io/library/api-reference\n",
    "https://streamlit.io/cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e244d01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile streamlit_app.py \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('dependency_treebank')\n",
    "nltk.download('snowball_data')\n",
    "nltk.download('rslp')\n",
    "nltk.download('porter_test')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('pros_cons')\n",
    "nltk.download('hmm_treebank_pos_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('treebank')\n",
    "nltk.download('reuters')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "\n",
    "def load(vectorizer_path, model_path):\n",
    "\n",
    "    # Load the vectorizer.\n",
    "    file = open(vectorizer_path, 'rb')\n",
    "    vectorizer = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    # Load the Logistic Regression Model.\n",
    "    file = open(model_path, 'rb')\n",
    "    LRmodel = pickle.load(file)\n",
    "    file.close()    \n",
    "    return vectorizer, LRmodel\n",
    "\n",
    "def predict(vectorizer, model, texts, cols):  \n",
    "    text = texts.split(\";\")    \n",
    "    finaldata = []\n",
    "    \n",
    "    textdata = vectorizer.transform((lemmatize_process(stemming_process(preprocess(text)))))\n",
    "    sentiment = model.predict(textdata)\n",
    "    sentimentp = model.predict_proba(textdata)\n",
    "    \n",
    "    for index,sentences in enumerate(text):\n",
    "        if sentiment[index] == -1:\n",
    "            sentimentpFinal = sentimentp[index][-1]\n",
    "        elif sentiment[index] == 0:  \n",
    "            sentimentpFinal = sentimentp[index][0]\n",
    "        else:  \n",
    "            sentimentpFinal = sentimentp[index][1]  \n",
    "            \n",
    "        sentimentpFinal3 = \"{}%\".format(round(sentimentpFinal*100,3))\n",
    "        finaldata.append((sentences, sentiment[index], sentimentpFinal3))\n",
    "           \n",
    "    # Convert the list into a Pandas DataFrame.\n",
    "    dfmessages = pd.DataFrame(finaldata, columns = ['sentences','sentiment', 'Probability']) \n",
    "    \n",
    "    # append new review and sentiment to existing dataframe\n",
    "    dfmessages2 = dfmessages[['sentences','sentiment']].replace([\"negative\",\"neutral\",\"positive\"],[-1,0,1] )\n",
    "    dfmessages2.to_csv('Restaurant_Reviews_pos_neu_neg.csv', mode='a', index=False, header=False)\n",
    "    \n",
    "    dfmessages = dfmessages.replace([-1,0,1], [\"negative\",\"neutral\",\"positive\"])      \n",
    "    return dfmessages    \n",
    "\n",
    "    \n",
    "def get_jvnr(tag):\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    if tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    if tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_process(preprocessedtext):\n",
    "    # Create lemmatizer\n",
    "    lem = WordNetLemmatizer()   \n",
    "    finalprocessedtext = []\n",
    "    for word in preprocessedtext:\n",
    "        text_pos = pos_tag(word_tokenize(word))\n",
    "        words = [x[0] for x in text_pos]\n",
    "        pos = [x[1] for x in text_pos]\n",
    "        word_stm = \" \".join([lem.lemmatize(a,get_jvnr(b)) for a,b in zip(words,pos)])\n",
    "        finalprocessedtext.append(word_stm)\n",
    "    return finalprocessedtext\n",
    "    \n",
    "def stemming_process(preprocessedtext):\n",
    "    # Create stemming\n",
    "    stm = PorterStemmer()   \n",
    "    finalprocessedtext = []\n",
    "    for word in preprocessedtext:\n",
    "        text_pos = pos_tag(word_tokenize(word))\n",
    "        words = [x[0] for x in text_pos]\n",
    "        pos = [x[1] for x in text_pos]\n",
    "        word_stm = \" \".join([stm.stem(a,get_jvnr(b)) for a,b in zip(words,pos)])\n",
    "        finalprocessedtext.append(word_stm)\n",
    "    return finalprocessedtext    \n",
    "\n",
    "def preprocess(preprocessedtext):     \n",
    "    processedText = []\n",
    "    for Review_data in preprocessedtext:\n",
    "        Review_data = str(Review_data).lower()\n",
    "        Review_data = re.sub(r'#[A-Za-z0–9]+', '', Review_data) #remove hashtags\n",
    "        Review_data=re.sub(r'@[A-Za-z0–9]+', '',Review_data) #remove usernames    \n",
    "        Review_data=re.sub(r'@\\w+', ' ', Review_data) #remove usernames\n",
    "        Review_data= re.sub(r'\\b\\w{1}\\b', '', Review_data) #remove stopwords   \n",
    "        Review_data = re.sub(r'&(?![A-Za-z]+[0-9]*;|#[0-9]+;|#x[0-9a-fA-F]+;)', '', Review_data)\n",
    "        Review_data = re.sub(r'&amp', '', Review_data) \n",
    "        Review_data = re.sub('\\n', '', Review_data) #Remove line breaks.\n",
    "        Review_data = re.sub('[%s]' % re.escape(string.punctuation), '', Review_data) #remove punctuation\n",
    "        Review_data = re.sub('\\[.*?\\]', '', Review_data)\n",
    "        Review_data=re.sub(r'http\\S+', ' ', Review_data) #remove all Url\n",
    "        Review_data = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', Review_data) #remove website\n",
    "        Review_data = re.sub('https?://\\S+|www\\.\\S+', '', Review_data)  #remove all websites \n",
    "        Review_data = re.sub(r' +', ' ', Review_data) #remove extra space\n",
    "        Review_data = re.sub('<.*?>+', '', Review_data)    \n",
    "        Review_data = re.sub('\\w*\\d\\w*', '', Review_data)\n",
    "        Review_data = re.sub(r'^RT[\\s]+', '', Review_data)    \n",
    "        Review_data = re.sub(r'[^a-z A-Z]', ' ',Review_data) #Remove all not characters        \n",
    "        processedText.append(Review_data)        \n",
    "    return processedText\n",
    "\n",
    "#to show  progress bar\n",
    "def show_progress():\n",
    "    the_bar = st.progress(0)\n",
    "    for percent_complete in range(100):\n",
    "        time.sleep(0.01)\n",
    "        the_bar.progress(percent_complete + 1)\n",
    "        \n",
    "#Create API\n",
    "st.title('Sentiment Analysis Application Tool')\n",
    "st.write('Sentiment Analysis Review Prediction')\n",
    "st.sidebar.subheader(\"Enter texts here, separated by semicolon\")\n",
    "texts = st.sidebar.text_area(\"Examples\", value=\"The food is good; The juice is too sour; I feel disappointed\", height=70, max_chars=None, key=None)\n",
    "cols = [\"texts\"]\n",
    "   \n",
    "if (st.sidebar.button('Predict Sentiment')):   #to create progress bar\n",
    "    show_progress() #to show  progress bar\n",
    "    \n",
    "    vectorizer, model = load('vectorizer.pickle', 'sentimentanalysis_LR.pickle')                              \n",
    "    result_df = predict(vectorizer, model, texts, cols)\n",
    "    st.table(result_df)\n",
    "    st.text(\"\")\n",
    "    st.text(\"\")\n",
    "    st.text(\"\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6682134",
   "metadata": {},
   "source": [
    "##### In command prompt type: C:>streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da801d2f",
   "metadata": {},
   "source": [
    "### Iterative optimization of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cee8adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved\n",
      "training done\n"
     ]
    }
   ],
   "source": [
    "#Automate scheduled training    \n",
    "\n",
    "train_models()\n",
    "schedule.every(24).hours.do(train_models)\n",
    "print(\"training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f165f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
